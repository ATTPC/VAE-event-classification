{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from data_loader import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event=\"0210\"\n",
    "size =\"128\"\n",
    "#a = np.load(\"../data/real/images/run_\"+event+\"_label_True_size_\"+size+\".npy\")\n",
    "x_set = np.load(\"../data/latent/clf_latent/vgg_data_repr.npy\")\n",
    "y_set = np.load(\"../data/latent/clf_latent/targets.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x, y = load_real_event(\"128\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(x_set[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 1\n",
    "data = x_set[which]\n",
    "targets = y_set[which]\n",
    "true_class = targets.argmax(1)\n",
    "\n",
    "pca_repr = PCA(50).fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_red = TSNE(2, perplexity=15, init=\"pca\")\n",
    "data_to_plot = dim_red.fit_transform(pca_repr)\n",
    "#print(dim_red.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "classes = [\"Proton\", \"Carbon\", \"Other\"]\n",
    "for c in np.unique(true_class):\n",
    "    w = true_class == c\n",
    "    ax.scatter(data_to_plot[w][:,0], data_to_plot[w][:,1], alpha=0.4, label=classes[c])\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(input_shape, n_classes=2, lmd=0.2):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(\n",
    "        keras.layers.Dense(\n",
    "        n_classes,\n",
    "        input_shape=input_shape,\n",
    "        kernel_regularizer=\"l2\",\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        keras.layers.BatchNormalization()\n",
    "    )\n",
    "    model.add(\n",
    "        keras.layers.Activation(\"sigmoid\")\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_model(input_dim):\n",
    "    input_layer = Input(shape=input_dim)\n",
    "    vgg = VGG16(include_top=False, input_tensor=input_layer)\n",
    "    which_o = 3\n",
    "    o = Flatten()(vgg.layers[which_o].output)\n",
    "    return Model(inputs=input_layer, outputs=o)\n",
    "    \n",
    "def resnet_model(input_dim):\n",
    "    input_layer = Input(shape=input_dim)\n",
    "    res_net = ResNet50(include_top=False, input_tensor=input_layer)\n",
    "    o = Flatten()(res_net.output)\n",
    "    return Model(inputs=input_layer, outputs=o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg_model((128, 128, 3))\n",
    "model_repr = model.predict(np.concatenate([x, x, x], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_repr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(1500, svd_solver=\"randomized\")\n",
    "pca.fit(model_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_repr = pca.transform(model_repr)\n",
    "#pca_vgg_test = pca.transform(vgg_model.predict(original_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtr, xte, ytr, yte = train_test_split(pca_repr, y)\n",
    "clf_model = RandomForestClassifier(max_features=0.1, class_weight=\"balanced\")\n",
    "clf_model.fit(xtr, ytr)\n",
    "print(clf_model.score(xte, yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important = clf_model.feature_importances_ > 1e-2\n",
    "plt.hist(clf_model.feature_importances_[important])\n",
    "most_import = np.argsort(-clf_model.feature_importances_)[:2]\n",
    "print(most_import)\n",
    "pca_2dim = pca_repr[:, most_import]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_m = y.argmax(1)\n",
    "classes = np.unique(y_m)\n",
    "for c in classes:\n",
    "    which = y_m == c\n",
    "    plt.scatter(pca_2dim[which,0], pca_2dim[which,1], label=classes[c])\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "cluster_model = MiniBatchKMeans(\n",
    "    n_clusters=3,\n",
    "    batch_size=150,\n",
    "    n_init=100,\n",
    "    )\n",
    "cluster_model.fit(pca_vgg_train)\n",
    "train_pred = cluster_model.predict(pca_vgg_train)\n",
    "test_pred = cluster_model.predict(pca_vgg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_distance(x, y, weight_func=lambda x: x):\n",
    "    \"\"\"\n",
    "    x and y should  be T by L matrices \n",
    "    this function measures  euclidian distance along T\n",
    "    and reduces to a float along L \n",
    "    \"\"\"\n",
    "    \n",
    "    sub = x - y \n",
    "    sub = weight_func(sub)\n",
    "    \n",
    "    tmp = np.power(sub, 2)\n",
    "    tmp = np.sum(tmp, axis=1)\n",
    "    tmp = np.sqrt(tmp,)\n",
    "    \n",
    "    return np.sum(tmp)\n",
    "\n",
    "def euclidian(x, y):\n",
    "    return(np.sqrt(np.sum(np.power(x-y, 2))))\n",
    "\n",
    "n_events = pca_vgg_train.shape[0]\n",
    "train_dist_matrix = np.zeros((n_events, n_events))\n",
    "\n",
    "n_test = pca_vgg_test.shape[0]\n",
    "test_dist_matrix = np.zeros((n_test, n_test))\n",
    "\n",
    "T = np.expand_dims(np.arange(pca_vgg_train.shape[0],), -1)\n",
    "linear_weight = lambda x: x/(1 + T )\n",
    "\n",
    "for i in range(n_events):\n",
    "    for j in range(n_events):\n",
    "        #dist_matrix[i, j] = latent_distance(original_latent[:, i, :], original_latent[:, j, :], weight_func=linear_weight)\n",
    "        train_dist_matrix[i, j] = euclidian(pca_vgg_train[i, :], pca_vgg_train[j, :])\n",
    "        \n",
    "\n",
    "for i in range(n_test):\n",
    "    for j in range(n_test):\n",
    "        #dist_matrix[i, j] = latent_distance(original_latent[:, i, :], original_latent[:, j, :], weight_func=linear_weight)\n",
    "        test_dist_matrix[i, j] = euclidian(pca_vgg_test[i, :], pca_vgg_test[j, :])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "flat_dist = train_dist_matrix.flatten()\n",
    "flat_dist.sort()\n",
    "plt.plot(flat_dist, \"ko\", alpha=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "cluster_model = DBSCAN(\n",
    "                eps=200,\n",
    "                metric=\"precomputed\",\n",
    "                min_samples=8\n",
    "            )\n",
    "\n",
    "train_pred = cluster_model.fit_predict(train_dist_matrix)\n",
    "#test_pred = cluster_model.transform(test_dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "\n",
    "\n",
    "a = plot_confusion_matrix(train_targets, train_pred, [\"proton\", \"carbon\", \"junk\"])\n",
    "a.set_title(\"Confusion matrix for Train\")\n",
    "\n",
    "print(\"Scores on Train: \")\n",
    "print(\"ARI : \", adjusted_rand_score(train_targets, train_pred))\n",
    "print(\"NMI : \", normalized_mutual_info_score(train_targets, train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = plot_confusion_matrix(test_targets, test_pred, [\"proton\", \"carbon\", \"junk\"])\n",
    "a.set_title(\"Confusion matrix for test\")\n",
    "\n",
    "\n",
    "print(\"Scores on Train: \")\n",
    "print(\"ARI : \", adjusted_rand_score(test_targets, test_pred))\n",
    "print(\"NMI : \", normalized_mutual_info_score(test_targets, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "projection = TSNE(2, perplexity=34, learning_rate=10).fit_transform(pca_vgg_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proton = projection[train_targets==0]\n",
    "carbon = projection[train_targets==1]\n",
    "junk = projection[train_targets==2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(proton[:,0], proton[:,1], c=\"r\", alpha=0.6)\n",
    "ax.scatter(carbon[:,0], carbon[:,1], c=\"g\", alpha=0.2)\n",
    "ax.scatter(junk[:,0], junk[:,1], c=\"b\", alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(projection[:,0], projection[:,1], alpha=0.2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (Conda)",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
